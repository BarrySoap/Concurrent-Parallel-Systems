\documentclass[12pt, a4paper]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[parfill]{parskip}
\usepackage{graphicx}
\usepackage{float}
\usepackage[english]{babel}
\usepackage[top=1.0in, bottom=1.0in, left=1.0in, right=1.0in]{geometry}
\graphicspath{{Images/}}
\linespread{1.25}

\title{\vspace{-3cm}Concurrent \& Parallel Systems - Coursework 1 Report}

\author{Glenn Wilkie-Sullivan - 40208762}

\date{\today}

\makeatletter
\newcommand{\mypm}{\mathbin{\mathpalette\@mypm\relax}}
\newcommand{\@mypm}[2]{\ooalign{%
  \raisebox{.1\height}{$#1+$}\cr
  \smash{\raisebox{-.6\height}{$#1-$}}\cr}}
\makeatother

\begin{document}
\maketitle

\begin{abstract}
\noindent This report will detail a project attempting to add concurrency and parallelism within a block-chain simulator in C++. The project in question will utilise methods such as multi-threading, algorithmic skeletons, CPU-level parallelism and OpenMP (Open Multi-Processing) to optimise the simulator as much as possible.
\end{abstract}

\section{Introduction and Background}
This project will be analysing, parallelising and optimising a block-chain simulator using the SHA-256 hashing algorithm. According to investopedia, block-chain is, "primarily used to verify transactions, within digital currencies though it is possible to digitize, code and insert practically any document into the blockchain". Each block contains a hash of the previous block, some form of timestamp and data associated to the task, and each block is connected together in a chain resembling a tree-structure. 'SHA, or \textbf{S}ecure \textbf{H}ashing \textbf{A}lgorithm', is a form of cryptographic hash function used to create unique signatures for a data file. In this instance, the SHA-256 hashing algorithm is assigning an almost-unique 256-bit (32-byte) signature for each block.

\section{Initial Analysis}
In my analysis of the application, I used the following processor:
\begin{itemize}
\item Intel Core i7-6700HQ @ 2.60GHz (4 cores, 8 threads)
\end{itemize}
To analyse the performance and overall CPU usage of the blockchain application, I used the Visual Studio 2017 diagnostic tools - all within Release mode, x86. To start with, I ran the application to examine the overall performance, as well as any potential bottlenecks in the code. Unsurprisingly, the performance of the application hinges mainly on the 'difficulty' variable, which the programmer can control. After 5 runs, the application, with difficulty 5, mined 5 blocks in about 43 $\mypm$ 10 seconds. With difficulty 6, the application mined 5 blocks in about 382 $\mypm$ 30 seconds. \\
As for bottlenecking, the application has a few instances of it. The most effective method of finding the bottleneck was to use Visual Studio's debugging tools, between a range of difficulties. The results after running the application with difficulty 6 was as follows: \\

\begin{table}
    \centering
    \begin{tabular}{| l | l | l |}
    \hline
    Function & CPU Unit Usage & CPU Usage \%  \\ \hline
    block\_chain::add\_block() & 60052 & 99.46\% \\ \hline
    block::mine\_block() & 60033 & 99.43\% \\ \hline
    block::calculate\_hash() & 54385 & 90.08\% \\ \hline
    sha256 & 32785 & 54.30\% \\ \hline
    sprintf & 20667 & 34.23\% \\ \hline
    \end{tabular}
    \caption{Individual Function CPU Usage}
\end{table}
\medskip
From these values, I was able to delve into each individual method (add\_block, mine\_block, calculate\_hash) - which let me see the CPU usage for each line of code. The add\_block method runs the mine\_block method, which then runs the calculate\_hash method. Within this, the SHA-256 hashing function seems to be the main usage of CPU time. After using the diagnostic tools, the following CPU usage percentages were shown: \\

\begin{figure}[H]
	\centering
		\includegraphics[width=0.6\textwidth]{"LightSha"}
		\caption{SHA256 Function CPU Usage}
\end{figure}

As it is called within the main while loop of calculate\_hash, this line seems to be creating, appending and concatenating a hash-code until it is compared to a specific string, which is passed as a termination condition in the while loop. In order to understand how many times this hashing function is called, I simply added a value which will count the amount of times the function runs. Given that 1000 blocks are mined, the application had to be ran at lower difficulties to test this. The following results were found: \\

\begin{table}[H]
    \centering
    \begin{tabular}{| l | l | l |}
    \hline
    Difficulty & Iterations & \% increase from previous difficulty \\ \hline
    1 & 15,719 & N/A \\ \hline
    2 & 253,078 & 1,510\% \\ \hline
    3 & 3,989,869 & 1,476.5\% \\ \hline
    4 & 62,918,025 & 1,476.9\% \\ \hline
    \end{tabular}
    \caption{Hashing Iterations}
\end{table}

From this, we can safely say that each step in difficulty will have roughly the same \% increase. Based on these exponential values, it is clear why a bottleneck occurs within this function. Using this \% increase, we can estimate a mining of 1000 blocks at difficulty 5 to have around 991,902,664 iterations. At difficulty 6, 15,637,345,497 iterations. Assuming this function can be ran multiple times concurrently, that theoretically should decrease execution time by a substantial amount - however, creating threads specifically for this function may be costly itself. Another line worth considering is the initialisation of the stringstream which is passed as a parameter to the hashing algorithm. As seen below, the following CPU usage for each line can be seen, \\

\begin{table}[H]
    \centering
    \begin{tabular}{| l | l |}
    \hline
    Function & CPU Usage \%  \\ \hline
    stringstream initialisation & $\approx$ 1.82\% \\ \hline
    stringstream concatenation & $\approx$ 20.00\% \\ \hline
    sha256 hashing & $\approx$ 64.13\% \\ \hline
    Other/Tertiary Processes & $\approx$ 10 - 14\% \\ \hline
    \end{tabular}
    \caption{Individual Line CPU Usage}
\end{table}

The stringstream initialisation uses 20\% of the CPU resource, as opposed to the hashing function's 64\% - this is likely due to the amount of times the stringstream object is being initialised. Moving the object constructor out of this method would likely increase the program speedup somewhat. This is the main bottleneck of the application - no other function/method comes close to the amount of CPU resource that the hashing algorithm uses. 

\section{Methodology}
Due to its overall effect on the application, we can safely assume that editing/optimising the stringstream initialisation and hashing algorithm should improve the efficiency and speedup in multiple areas of the program. Parallelising the algorithm should be the most effective method of optimisation, and there are multiple string functions which are better suited, performance wise, than stringstreams - such as string::reserve and string::append. These functions can request a change in size to our hashcode, then append the necessary information respectively. \\
To start with, it would be beneficial to make small changes to the way the program operates - there are superfluous print statements, some values can be placed in the header file(s), and some functions can be edited slightly. In order to measure the speedup and efficiency, I'll have to serialise the times of the mined blocks, and see if any noticable change in time occurs before and after the changes are made. To do this, the time value can be placed into a CSV file for each block, and we can use R to draw comparison between two datasets. We can do this for all methods of optimisation in the future. \\
Next, we can use threads and OpenMP to parallelise the hashing algorithm, such that there are hashing processes running on 8 threads (relative to CPU) instead of running them sequentially. After examining the results of a successful or non-successful parallelisation, we must consider the other utilities offered from parallelisation. When creating threads for our parallisation, it may prove useful to use a mutex and atomics to ensure the consistency of our hashcodes. We can ensure that only one thread is operating within the hashcode generation/concatenation to avoid deadlock, and use atomic functions to make sure the hashcode isn't split during the process execution(s). Outside of the hashing algorithm, the application may benefit from parallel for loops as opposed to generic for/while loops. Since we either know or can approximate how many times a loop will run in this application, it would be a good idea to parallelise these processes. Likewise, we can use scheduling to divide work in our parallel loops - especially since we have a predetermined amount of blocks to mine. \\
Once these features are in place, we can measure efficiency and speedup using a table similar to this,

\begin{table}[H]
    \centering
    \begin{tabular}{| l | l | l |}
    \hline
    Feature & Time Before Implementation & Time After Implementation \\ \hline
    string::append & x seconds & y seconds \\ \hline
    Hashing Parallelisation & x seconds & y seconds \\ \hline
    General Parallelisation & x seconds & y seconds \\ \hline
    \end{tabular}
    \caption{Optimisation Approaches}
\end{table}

\section{Results and Discussion}
In order to examine the speedup and efficiency for the application, there had to be some way to compare the mining time for different methodologies. With that in mind, there had to be separate Visual Studio projects with the original scripts, and every methodology used for this project. However, all of these projects had to have functions which serialised the average time to mine blocks, as well as the difficulty. This can then be visualised and examined with a simple R script, which simply reads in the data, transforms it into a data frame and plots it using the ggplot2 package. Any results seen in this section won't be influenced by background processes or other programs - these were closed/stopped. To examine the application, the methods used were: thread pools, multithreading and OpenMP. The average speed for a block to be mined was compared against the speed of the original scripts, which produced the following graph: \\

\begin{figure}[H]
	\centering
		\includegraphics[width=0.8\textwidth]{"Times"}
		\caption{Average Block Mining Time Between Methods}
\end{figure}
From figure 2, we can see that all methods are somewhat equal in their cumulative time for the lower difficulties, but OpenMP and multithreading will take a bit longer as they both have to initialise threads in the code. However, further down the line this pays off for only multithreading. We will examine this more throughly: \\

To start with, we must examine the multithreading method. This entails creating n amount of threads, relative to the CPU, and having the threads work on facets of the application in parallel. In order to achieve this, we have to replace a costly, sequential function with a purely threaded method of execution - the chosen function to replace was the calculate hash function. As mentioned previously, this can be called millions, possibly even billions of times at higher difficulties. Having a threaded method to execute this would speed up the application considerably. Upon replacing the function, the following results were found:

\begin{table}[H]
    \centering
    \begin{tabular}{| l | l | l | l |}
    \hline
    Difficulty & Time Taken (Sequential) & Time Taken (Threaded) & Speedup\\ \hline
    1 & 0.222963 seconds & 0.743006 seconds & N/A\\ \hline
    2 & 0.444432 seconds & 0.751788 seconds & N/A\\ \hline
    3 & 4.66663 seconds & 1.80038 seconds & 2.59202\\ \hline
    4 & 57.9695 seconds & 15.6473 seconds & 3.70476\\ \hline
    5 & 933.004 seconds & 207.502 seconds & 4.49636\\ \hline
    \end{tabular}
    \caption{Performance Difference (Sequential vs. Multithreading)}
\end{table}

From this table, we can see a 4.4 total speedup in favour of the multithreading technique, with an efficiency of 0.999987. From this, we can safely say that multithreading is a better solution than sequentially running the program - at lower difficulties, the multithreaded approach takes longer to compute, as the creation of threads is more costly on the CPU than the amount of iterations the hashing function runs through. However, as the amount of iterations increases, proportional to the difficulty, the thread initialisation becomes much more efficient, and an overall better option. With more time, another avenue to explore would be the inclusion of mutexes, guards and futures. Mutexes and guards would assure the safety of the hash in this application, and futures may be useful for having the CPU carry out multiple operations on the hash function at once. \\

The next technique to examine is the OpenMP method. This entails using the shared memory multiprocessing interface, Open MultiProcessing, to introduce parallel looping in the application. This method has a lot more leniency on where it can be used within the application - due to the number of functions within the code, we can add parallel loops to the block chain functions, the main functions or the hashing functions. First, we will look at the use of OpenMP on the blockchain functions and the hashing function. The following results were found after a parallel loop was added to the calculate\_hash and hashing function: 

\begin{table}[H]
    \centering
    \begin{tabular}{| l | l | l | l |}
    \hline
    Difficulty & Time Taken (Sequential) & Time Taken (OpenMP) & Speedup\\ \hline
    1 & 0.222963 seconds & 0.259078 seconds & N/A \\ \hline
    2 & 0.444432 seconds & 2.37753 seconds & N/A \\ \hline
    3 & 4.66663 seconds & 30.5151 seconds & N/A \\ \hline
    4 & 57.9695 seconds & 414.141+ seconds & N/A \\ \hline
    5 & 933.004 seconds & ?? seconds & N/A \\ \hline
    \end{tabular}
    \caption{Performance Difference (Sequential vs. OpenMP)}
\end{table}

Unfortunately, when testing OpenMP, the time between difficulties was exponentially larger each step. It took roughly 414 seconds to mine 18 blocks at difficulty 4, which means that there was a mistake in implementation. Based on the parallel loops within the code, it seems that although there are 8 threads operating on the hashing function, it's only possible to have one thread work on the function at a time - in order to retain the integrity of the hashcode. We can safely assume that for each iteration, either one thread or eight threads are being initialised to share resources among the function call. This explains why it takes so long as the difficulties get larger - there is, roughly, a 1,475\% increase in the amount of iterations as the difficulty increases, which applies to the thread creation. \\
Another method which was investigated in this project was using an OpenMP on the initialisation of the block chain. Within the application, it is possible, and most likely efficient, to handle multiple difficulties on each run of the program. In theory, it should be possible to use OpenMP to mine blocks for two difficulties at once, seeing as the loops are in parallel. However, upon putting this into application, the process requires a lot more work to guarantee the integrity of the mining process and the hashcodes. When attempting to run multiple difficulties at once, the parallel loop will attempt to mine blocks without taking the hash of the previous block - which may still be being mined. In order for this to work, there has to be a function which can emulate a mutex or a lock guard, in order to make sure that the loop doesn't try to mine blocks which are too far ahead of the process. Finally, when trying to use OpenMP to parallelise the sprintf function within the application (the main bottleneck of the program) there were shared resource issues stemming from the contents of the buffer. The OpenMP functions would have to work in a perfect order for the sprintf function to be parallelised, which proved to be increasingly difficult.

\section{Conclusion}
Based on the results from the different methods of running this application, we can safely say that multithreading seems to be far more efficient executing the given tasks than the standard code or OpenMP. However, from numerous runs of the program and some background reading, it seems likely that the implementation of OpenMP functionality in this program is incorrect. The final result should run somewhat similar to the multithreaded approach, but may need a more abstracted approach to handle the blockchain and hashing algorithms. \\
We can safely conclude that the multithreaded approach gets exponentially more efficient and faster than the standard approach at higher difficulties due to the high percentage of increased iterations through the hashing function. There is reason to believe that in theory, the OpenMP implementation should be similar, although the results show differently.

\newpage

\bibliographystyle{apalike}
\bibliography{bib}{}
\nocite{*}

\end{document}